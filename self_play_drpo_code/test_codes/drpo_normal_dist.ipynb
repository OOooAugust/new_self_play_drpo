{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fe98f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/miniconda3/envs/myenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import sys, pathlib\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModelForSequenceClassification,DebertaV2ForSequenceClassification, GPTNeoXForCausalLM\n",
    "from llm_blender.pair_ranker.pairrm import DebertaV2PairRM\n",
    "from transformers import DataCollatorWithPadding\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset, concatenate_datasets, DatasetDict\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import yaml\n",
    "\n",
    "LOCAL_TRL_PARENT = \"/workspace/Self_play_DRPO\"\n",
    "if LOCAL_TRL_PARENT not in sys.path:\n",
    "    sys.path.insert(0, LOCAL_TRL_PARENT)\n",
    "\n",
    "    \n",
    "# now the import will use your local copy:\n",
    "from trl import (\n",
    "    DPOTrainer,\n",
    "    DPOConfig,\n",
    "    ModelConfig,\n",
    "    DRPOTrainer,\n",
    "    DRPOConfig,\n",
    ")\n",
    "from trl.trainer.utils import SIMPLE_CHAT_TEMPLATE\n",
    "from trl.data_utils import apply_chat_template\n",
    "from trl.trainer.drpo_utils import PairRMPipeline\n",
    "\n",
    "def process_split(original, seed = 42):\n",
    "    swapped = original.map(lambda x: {\n",
    "        'a1': x['a2'],\n",
    "        'a2': x['a1'],\n",
    "        # 'rank': 1 - int(random.random() < x['chosen_preference']),\n",
    "        'rank': 1 - x['rank'],\n",
    "    })\n",
    "\n",
    "    return concatenate_datasets([original, swapped]).shuffle(seed=seed)\n",
    "\n",
    "def load_model(model_path, task = 'generation', model_type = 'decoder', model_cache_path =  '/workspace/model_cache'):\n",
    "\n",
    "    model_args = ModelConfig(model_path)\n",
    "    model_torch_dtype = torch.bfloat16\n",
    "    model_kwargs = dict(\n",
    "    revision = model_args.model_revision,\n",
    "    torch_dtype = model_torch_dtype, \n",
    "    trust_remote_code = model_args.trust_remote_code,\n",
    "    )\n",
    "\n",
    "    padding_side = 'left' if model_type == 'decoder' else 'right'\n",
    "    truncation_side = 'left' if model_type == 'decoder' else 'right'\n",
    "\n",
    "    if task == 'generation':\n",
    "        model_instance = AutoModelForCausalLM.from_pretrained(\n",
    "            model_args.model_name_or_path,\n",
    "            **model_kwargs,\n",
    "            cache_dir = model_cache_path,\n",
    "        )\n",
    "\n",
    "    elif task == 'reward':\n",
    "        model_instance = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_args.model_name_or_path,\n",
    "            **model_kwargs,\n",
    "            cache_dir = model_cache_path,\n",
    "        )\n",
    "    \n",
    "\n",
    "    model_tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_args.model_name_or_path, \n",
    "        padding_side = padding_side, \n",
    "        truncation_side = truncation_side,\n",
    "        use_fast = True,\n",
    "        trust_remote_code = model_args.trust_remote_code,\n",
    "        cache_dir = model_cache_path\n",
    "    )\n",
    "\n",
    "    if model_tokenizer.pad_token is None:\n",
    "        model_tokenizer.pad_token = model_tokenizer.eos_token\n",
    "\n",
    "    if getattr(model_instance.config, \"pad_token_id\", None) is None:\n",
    "        model_instance.config.pad_token_id = model_tokenizer.pad_token_id\n",
    "\n",
    "    if model_tokenizer.eos_token is None:\n",
    "        model_tokenizer.eos_token = model_tokenizer.pad_token  \n",
    "\n",
    "    if getattr(model_instance.config, \"eos_token_id\", None) is None:\n",
    "        model_instance.config.eos_token_id = model_tokenizer.eos_token_id\n",
    "\n",
    "    return model_instance, model_tokenizer\n",
    "\n",
    "\n",
    "\n",
    "data_cache_path = \"/workspace/dataset\"\n",
    "model_cache_path = '/workspace/model_cache'\n",
    "ds_path = 'august66/drpo_hh_qwen2.5_1.5b'\n",
    "ref_policy_path = \"Qwen/Qwen2.5-1.5B-Instruct\" \n",
    "target_policy_path = \"Qwen/Qwen2.5-1.5B-Instruct\" \n",
    "dpo_policy_path = 'august66/hh_qwen_1.5b_dpo_model_2'\n",
    "\n",
    "#load training argument for drpo\n",
    "with open(\"/workspace/Self_play_DRPO/self_play_drpo_code/training_config/config_normal_dist.yaml\", \"r\") as f:\n",
    "    training_args_config = yaml.safe_load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c1bbb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after chat template dataset sample: {'prompt': \"<|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nAny tips on how to revise something you wrote?<|im_end|>\\n<|im_start|>assistant\\nThat depends on what you mean by revise, I think. Do you mean you’ve already written something and you want to fix mistakes and add detail, or do you want to make some major changes?<|im_end|>\\n<|im_start|>user\\nCould be either. It's a hypothetical scenario. I'm not actually rewriting or revising anything. I just want your advice on how to do this.<|im_end|>\\n<|im_start|>assistant\\nOK, that’s fine. If it’s hypothetical, then I’m happy to talk about whatever you have in mind, if it’s a useful topic of conversation.<|im_end|>\\n<|im_start|>user\\nSo what's your advice for rewrite or revision?<|im_end|>\\n<|im_start|>assistant\\n\", 'a1': \"Rewriting or revising can be a challenging task, but there are a few general tips that may help:\\n\\n  1. Take a break: Sometimes taking a break from the writing can help clear your head and provide fresh perspective.\\n  2. Get feedback: Ask someone else to read your work and offer feedback. They may see things that you don’t notice right away.\\n  3. Check grammar and spelling: Make sure your sentences are grammatically correct and free of typos.\\n  4. Focus on clarity: Make sure your ideas are easy to understand and follow.\\n  5. Edit ruthlessly: Don't hold back when making edits. Strive to improve your work as much as possible.\\n\\nRemember, the goal is to write something that reads well and communicates your message effectively. Good luck!<|im_end|>\\n\", 'a2': \"Rewriting or revising is an essential part of the writing process, no matter where you are in your creative journey. Here are some general tips:\\n\\n1. **Identify Your Goals**: Before you start rewriting, define what you're trying to achieve with the piece. Are you looking to improve clarity, flow, style, depth, accuracy, tone, voice, or something else?\\n\\n2. **Understand Your Audience**: Consider who will read your work. This can influence your choice of language, tone, and level of detail.\\n\\n3. **Seek Feedback**: Share your draft with trusted peers, mentors, or members of your community. Constructive criticism can provide valuable insights into areas needing improvement.\\n\\n4. **Read Your Work Out Loud**: Sometimes reading your text out loud can help you catch awkward phrasing, missing words, or overly complex sentences that might confuse readers.\\n\\n5. **Use Writing Tools**: Utilize tools like Grammarly, Hemingway Editor, or other readability scores that highlight potential issues like passive voice usage, unclear verbs, or redundant phrases.\\n\\n6. **Delete and Simplify**: When revising, consider deleting any elements that aren’t necessary for conveying your message effectively. Streamline descriptions and eliminate unnecessary details.\\n\\n7. **Improve Paragraph Structure**: Ensure each paragraph flows smoothly from one idea to another without abrupt transitions. Each paragraph should contain a single main point and a few supporting points.\\n\\n8. **Focus on Clarity**: Strive for clarity and simplicity. Avoid jargon unless you’re sure your audience understands its meaning.\\n\\n9. **Revise Regularly**: Set aside time periodically during the editing phase to review and refine parts of the document rather than doing everything all at once.\\n\\n10. **Consistency Check**: Make sure consistency exists throughout your writing—consistent spelling, grammar, formatting, etc.\\n\\nEach writer finds their own way of approaching revision based on personal strengths and weaknesses, but following these guidelines generally leads to improved drafts. Remember, good writing evolves over time as you learn more about yourself as a writer and refine your craft.<|im_end|>\\n\", 'rank': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing train dataset: 100%|██████████| 87670/87670 [01:42<00:00, 854.65 examples/s]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mooooaugust\u001b[0m (\u001b[33mooooaugust-london-school-of-economics-and-political-science\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/Self_play_DRPO/self_play_drpo_code/test_codes/wandb/run-20250909_024141-hgv0fyqc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ooooaugust-london-school-of-economics-and-political-science/huggingface/runs/hgv0fyqc' target=\"_blank\">usual-terrain-128</a></strong> to <a href='https://wandb.ai/ooooaugust-london-school-of-economics-and-political-science/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ooooaugust-london-school-of-economics-and-political-science/huggingface' target=\"_blank\">https://wandb.ai/ooooaugust-london-school-of-economics-and-political-science/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ooooaugust-london-school-of-economics-and-political-science/huggingface/runs/hgv0fyqc' target=\"_blank\">https://wandb.ai/ooooaugust-london-school-of-economics-and-political-science/huggingface/runs/hgv0fyqc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated   (GB): 11.409146785736084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated   (GB): 13.402694702148438\n",
      "Allocated   (GB): 13.40269660949707\n",
      "Allocated   (GB): 13.402700424194336\n",
      "{'reward': 0.028594970703125, 'kl_ref_theta_star': 121.0, 'kl_theta_ref': -0.007459861692041159, 'kl_theta_theta_star': 83.57323455810547, 'scale': 3.0}\n",
      "Allocated   (GB): 13.95131254196167\n",
      "Allocated   (GB): 16.071962356567383\n",
      "Allocated   (GB): 16.071961879730225\n",
      "Allocated   (GB): 16.07196807861328\n",
      "{'reward': 0.05770111083984375, 'kl_ref_theta_star': 162.0, 'kl_theta_ref': 0.0010937975021079183, 'kl_theta_theta_star': 84.36793518066406, 'scale': 3.0}\n",
      "Allocated   (GB): 14.871642589569092\n",
      "Allocated   (GB): 17.227574825286865\n",
      "Allocated   (GB): 17.227578163146973\n",
      "Allocated   (GB): 17.22758197784424\n",
      "{'reward': 0.457000732421875, 'kl_ref_theta_star': 90.5, 'kl_theta_ref': 0.003996164072304964, 'kl_theta_theta_star': 121.81249237060547, 'scale': 3.0}\n",
      "Allocated   (GB): 13.883245944976807\n",
      "Allocated   (GB): 15.92759895324707\n",
      "Allocated   (GB): 15.927598476409912\n",
      "Allocated   (GB): 15.927605152130127\n",
      "{'reward': 0.115814208984375, 'kl_ref_theta_star': 92.5, 'kl_theta_ref': 0.001665080664679408, 'kl_theta_theta_star': 126.34687805175781, 'scale': 3.0}\n",
      "Allocated   (GB): 15.122402667999268\n",
      "Allocated   (GB): 17.684645175933838\n",
      "Allocated   (GB): 17.68464994430542\n",
      "Allocated   (GB): 17.684653282165527\n",
      "{'reward': -0.388397216796875, 'kl_ref_theta_star': 127.5, 'kl_theta_ref': -0.025133872404694557, 'kl_theta_theta_star': 142.76956176757812, 'scale': 3.0}\n",
      "Allocated   (GB): 14.239113330841064\n",
      "Allocated   (GB): 16.626938819885254\n",
      "Allocated   (GB): 16.62693977355957\n",
      "Allocated   (GB): 16.62694501876831\n",
      "{'reward': -0.082305908203125, 'kl_ref_theta_star': 91.5, 'kl_theta_ref': -0.006430370267480612, 'kl_theta_theta_star': 56.682655334472656, 'scale': 3.0}\n",
      "Allocated   (GB): 14.171292304992676\n",
      "Allocated   (GB): 15.806638717651367\n",
      "Allocated   (GB): 15.806640148162842\n",
      "Allocated   (GB): 15.80664348602295\n",
      "{'reward': 0.8892822265625, 'kl_ref_theta_star': 127.0, 'kl_theta_ref': 0.0004958296194672585, 'kl_theta_theta_star': 154.00143432617188, 'scale': 3.0}\n",
      "Allocated   (GB): 13.949561595916748\n",
      "Allocated   (GB): 15.596191883087158\n",
      "Allocated   (GB): 15.596192359924316\n",
      "Allocated   (GB): 15.59619665145874\n",
      "{'reward': -0.00020599365234375, 'kl_ref_theta_star': 84.5, 'kl_theta_ref': 0.00029619509587064385, 'kl_theta_theta_star': 84.23878479003906, 'scale': 3.0}\n",
      "Allocated   (GB): 14.765345573425293\n",
      "Allocated   (GB): 18.107415676116943\n",
      "Allocated   (GB): 18.1074161529541\n",
      "Allocated   (GB): 18.10742473602295\n",
      "{'reward': -0.38262939453125, 'kl_ref_theta_star': 135.0, 'kl_theta_ref': -0.04349837452173233, 'kl_theta_theta_star': 141.95840454101562, 'scale': 3.0}\n",
      "Allocated   (GB): 14.593133449554443\n",
      "Allocated   (GB): 18.451133728027344\n",
      "Allocated   (GB): 18.451132774353027\n",
      "Allocated   (GB): 18.45114517211914\n",
      "{'reward': -0.509124755859375, 'kl_ref_theta_star': 110.0, 'kl_theta_ref': 0.021847371011972427, 'kl_theta_theta_star': 132.6301727294922, 'scale': 3.0}\n",
      "Allocated   (GB): 14.906338214874268\n",
      "Allocated   (GB): 18.595722675323486\n",
      "Allocated   (GB): 18.595722675323486\n",
      "Allocated   (GB): 18.595734119415283\n",
      "{'reward': 0.31396484375, 'kl_ref_theta_star': 82.0, 'kl_theta_ref': 0.04301434010267258, 'kl_theta_theta_star': 72.98672485351562, 'scale': 3.0}\n",
      "Allocated   (GB): 14.135071754455566\n",
      "Allocated   (GB): 15.968994617462158\n",
      "Allocated   (GB): 15.968995571136475\n",
      "Allocated   (GB): 15.968999862670898\n",
      "{'reward': -0.22198486328125, 'kl_ref_theta_star': 75.0, 'kl_theta_ref': -0.007102167699486017, 'kl_theta_theta_star': 89.60348510742188, 'scale': 3.0}\n",
      "Allocated   (GB): 15.272856712341309\n",
      "Allocated   (GB): 20.010375499725342\n",
      "Allocated   (GB): 20.010375499725342\n",
      "Allocated   (GB): 20.01038885116577\n",
      "{'reward': 0.6533203125, 'kl_ref_theta_star': 69.5, 'kl_theta_ref': 0.01972721517086029, 'kl_theta_theta_star': 74.66058349609375, 'scale': 3.0}\n",
      "Allocated   (GB): 14.753788471221924\n",
      "Allocated   (GB): 17.351795196533203\n",
      "Allocated   (GB): 17.351798057556152\n",
      "Allocated   (GB): 17.351803302764893\n",
      "{'reward': -0.59832763671875, 'kl_ref_theta_star': 114.5, 'kl_theta_ref': -0.003866895567625761, 'kl_theta_theta_star': 156.50643920898438, 'scale': 3.0}\n",
      "Allocated   (GB): 14.292075634002686\n",
      "Allocated   (GB): 16.793710708618164\n",
      "Allocated   (GB): 16.793711185455322\n",
      "Allocated   (GB): 16.793717861175537\n",
      "{'reward': -0.14703369140625, 'kl_ref_theta_star': 105.0, 'kl_theta_ref': -0.018456419929862022, 'kl_theta_theta_star': 120.10235595703125, 'scale': 3.0}\n",
      "Allocated   (GB): 14.98627758026123\n",
      "Allocated   (GB): 16.652113437652588\n",
      "Allocated   (GB): 16.652119159698486\n",
      "Allocated   (GB): 16.652119159698486\n",
      "{'reward': -1.74578857421875, 'kl_ref_theta_star': 117.5, 'kl_theta_ref': -0.008136586286127567, 'kl_theta_theta_star': 142.45762634277344, 'scale': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='5480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   9/5480 32:56 < 429:09:16, 0.00 it/s, Epoch 0.00/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.005700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated   (GB): 17.476655960083008\n",
      "Allocated   (GB): 19.952197074890137\n",
      "Allocated   (GB): 19.95219898223877\n",
      "Allocated   (GB): 19.952205181121826\n",
      "{'reward': 1.55731201171875, 'kl_ref_theta_star': 94.5, 'kl_theta_ref': 0.28174740076065063, 'kl_theta_theta_star': 102.5602035522461, 'scale': 3.0}\n",
      "Allocated   (GB): 19.718765258789062\n",
      "Allocated   (GB): 22.114320755004883\n",
      "Allocated   (GB): 22.114319801330566\n",
      "Allocated   (GB): 22.114327907562256\n",
      "{'reward': 0.0060272216796875, 'kl_ref_theta_star': 152.0, 'kl_theta_ref': 0.4056096374988556, 'kl_theta_theta_star': 102.4009780883789, 'scale': 3.0}\n",
      "Allocated   (GB): 20.48171615600586\n",
      "Allocated   (GB): 23.350520133972168\n",
      "Allocated   (GB): 23.350520610809326\n",
      "Allocated   (GB): 23.3505277633667\n",
      "{'reward': 0.1794891357421875, 'kl_ref_theta_star': 87.0, 'kl_theta_ref': 0.05697329342365265, 'kl_theta_theta_star': 75.77232360839844, 'scale': 3.0}\n",
      "Allocated   (GB): 20.254658222198486\n",
      "Allocated   (GB): 22.467305183410645\n",
      "Allocated   (GB): 22.46730661392212\n",
      "Allocated   (GB): 22.4673113822937\n",
      "{'reward': 0.55865478515625, 'kl_ref_theta_star': 163.0, 'kl_theta_ref': 0.10490488260984421, 'kl_theta_theta_star': 89.22709655761719, 'scale': 3.0}\n",
      "Allocated   (GB): 19.660550117492676\n",
      "Allocated   (GB): 20.804771423339844\n",
      "Allocated   (GB): 20.80477285385132\n",
      "Allocated   (GB): 20.80477523803711\n",
      "{'reward': 0.1847991943359375, 'kl_ref_theta_star': 56.25, 'kl_theta_ref': 0.054978784173727036, 'kl_theta_theta_star': 60.10892868041992, 'scale': 3.0}\n",
      "Allocated   (GB): 21.4685115814209\n",
      "Allocated   (GB): 25.50412607192993\n",
      "Allocated   (GB): 25.50412893295288\n",
      "Allocated   (GB): 25.504136085510254\n",
      "{'reward': -2.13812255859375, 'kl_ref_theta_star': 154.0, 'kl_theta_ref': 0.04131186753511429, 'kl_theta_theta_star': 110.03640747070312, 'scale': 3.0}\n",
      "Allocated   (GB): 19.343103408813477\n",
      "Allocated   (GB): 20.27515697479248\n",
      "Allocated   (GB): 20.275157928466797\n",
      "Allocated   (GB): 20.275160312652588\n",
      "{'reward': -0.02294158935546875, 'kl_ref_theta_star': 135.0, 'kl_theta_ref': 0.038430143147706985, 'kl_theta_theta_star': 44.534271240234375, 'scale': 3.0}\n",
      "Allocated   (GB): 19.877400875091553\n",
      "Allocated   (GB): 23.680863857269287\n",
      "Allocated   (GB): 23.68086051940918\n",
      "Allocated   (GB): 23.680874824523926\n",
      "{'reward': -0.4791107177734375, 'kl_ref_theta_star': 161.0, 'kl_theta_ref': 0.1102948933839798, 'kl_theta_theta_star': 111.58120727539062, 'scale': 3.0}\n",
      "Allocated   (GB): 19.77518653869629\n",
      "Allocated   (GB): 22.788115978240967\n",
      "Allocated   (GB): 22.788113594055176\n",
      "Allocated   (GB): 22.788124561309814\n",
      "{'reward': 0.1665191650390625, 'kl_ref_theta_star': 138.0, 'kl_theta_ref': 0.04358556121587753, 'kl_theta_theta_star': 72.37351989746094, 'scale': 3.0}\n",
      "Allocated   (GB): 19.55989170074463\n",
      "Allocated   (GB): 21.01539897918701\n",
      "Allocated   (GB): 21.01539945602417\n",
      "Allocated   (GB): 21.015402793884277\n",
      "{'reward': 0.01050567626953125, 'kl_ref_theta_star': 131.0, 'kl_theta_ref': 0.0045212311670184135, 'kl_theta_theta_star': 119.53079223632812, 'scale': 3.0}\n",
      "Allocated   (GB): 19.859432220458984\n",
      "Allocated   (GB): 21.362855911254883\n",
      "Allocated   (GB): 21.362857818603516\n",
      "Allocated   (GB): 21.362860202789307\n",
      "{'reward': 0.292266845703125, 'kl_ref_theta_star': 80.0, 'kl_theta_ref': 0.11200226843357086, 'kl_theta_theta_star': 178.56736755371094, 'scale': 3.0}\n",
      "Allocated   (GB): 20.87065553665161\n",
      "Allocated   (GB): 23.712133407592773\n",
      "Allocated   (GB): 23.712137699127197\n",
      "Allocated   (GB): 23.71214199066162\n",
      "{'reward': 0.4713134765625, 'kl_ref_theta_star': 67.0, 'kl_theta_ref': 0.1118798553943634, 'kl_theta_theta_star': 90.85149383544922, 'scale': 3.0}\n",
      "Allocated   (GB): 20.249237060546875\n",
      "Allocated   (GB): 22.57483196258545\n",
      "Allocated   (GB): 22.574833393096924\n",
      "Allocated   (GB): 22.574839115142822\n",
      "{'reward': 0.202880859375, 'kl_ref_theta_star': 96.5, 'kl_theta_ref': 0.04525785148143768, 'kl_theta_theta_star': 40.98453140258789, 'scale': 3.0}\n",
      "Allocated   (GB): 20.005698680877686\n",
      "Allocated   (GB): 20.971696376800537\n",
      "Allocated   (GB): 20.97170066833496\n",
      "Allocated   (GB): 20.971700191497803\n",
      "{'reward': -0.90179443359375, 'kl_ref_theta_star': 77.5, 'kl_theta_ref': 0.07203832268714905, 'kl_theta_theta_star': 84.67655181884766, 'scale': 3.0}\n",
      "Allocated   (GB): 20.239363193511963\n",
      "Allocated   (GB): 23.266879081726074\n",
      "Allocated   (GB): 23.266878604888916\n",
      "Allocated   (GB): 23.266887664794922\n",
      "{'reward': -0.150390625, 'kl_ref_theta_star': 157.0, 'kl_theta_ref': 0.20660769939422607, 'kl_theta_theta_star': 151.6120147705078, 'scale': 3.0}\n",
      "Allocated   (GB): 20.516008377075195\n",
      "Allocated   (GB): 23.076746940612793\n",
      "Allocated   (GB): 23.076749324798584\n",
      "Allocated   (GB): 23.076753616333008\n",
      "{'reward': 0.2961578369140625, 'kl_ref_theta_star': 67.5, 'kl_theta_ref': 0.17111164331436157, 'kl_theta_theta_star': 86.28369140625, 'scale': 3.0}\n",
      "Allocated   (GB): 17.46079444885254\n",
      "Allocated   (GB): 20.523382663726807\n",
      "Allocated   (GB): 20.523383617401123\n",
      "Allocated   (GB): 20.523391723632812\n",
      "{'reward': -0.46270751953125, 'kl_ref_theta_star': 138.0, 'kl_theta_ref': 0.08191423118114471, 'kl_theta_theta_star': 108.88265228271484, 'scale': 3.0}\n",
      "Allocated   (GB): 20.209371089935303\n",
      "Allocated   (GB): 22.584985733032227\n",
      "Allocated   (GB): 22.584986686706543\n",
      "Allocated   (GB): 22.584991931915283\n",
      "{'reward': 0.0268707275390625, 'kl_ref_theta_star': 93.0, 'kl_theta_ref': 0.013777732849121094, 'kl_theta_theta_star': 137.55252075195312, 'scale': 3.0}\n",
      "Allocated   (GB): 20.523071765899658\n",
      "Allocated   (GB): 24.096518516540527\n",
      "Allocated   (GB): 24.096518993377686\n",
      "Allocated   (GB): 24.096529483795166\n",
      "{'reward': 1.56365966796875, 'kl_ref_theta_star': 113.5, 'kl_theta_ref': 0.24872232973575592, 'kl_theta_theta_star': 117.1622314453125, 'scale': 3.0}\n",
      "Allocated   (GB): 20.45504379272461\n",
      "Allocated   (GB): 24.439950942993164\n",
      "Allocated   (GB): 24.43994951248169\n",
      "Allocated   (GB): 24.43996286392212\n",
      "{'reward': 0.24652099609375, 'kl_ref_theta_star': 135.0, 'kl_theta_ref': 0.42243194580078125, 'kl_theta_theta_star': 125.83781433105469, 'scale': 3.0}\n",
      "Allocated   (GB): 19.689704418182373\n",
      "Allocated   (GB): 21.566385746002197\n",
      "Allocated   (GB): 21.566385746002197\n",
      "Allocated   (GB): 21.566391468048096\n",
      "{'reward': 1.238616943359375, 'kl_ref_theta_star': 139.0, 'kl_theta_ref': 0.11392740905284882, 'kl_theta_theta_star': 81.4609146118164, 'scale': 3.0}\n",
      "Allocated   (GB): 19.70158052444458\n",
      "Allocated   (GB): 20.721542358398438\n",
      "Allocated   (GB): 20.72154426574707\n",
      "Allocated   (GB): 20.721545696258545\n",
      "{'reward': 0.551239013671875, 'kl_ref_theta_star': 111.0, 'kl_theta_ref': 0.17714829742908478, 'kl_theta_theta_star': 89.0152359008789, 'scale': 3.0}\n",
      "Allocated   (GB): 19.75549602508545\n",
      "Allocated   (GB): 21.50812578201294\n",
      "Allocated   (GB): 21.508126258850098\n",
      "Allocated   (GB): 21.50813055038452\n",
      "{'reward': -0.4212493896484375, 'kl_ref_theta_star': 170.0, 'kl_theta_ref': 0.10403135418891907, 'kl_theta_theta_star': 98.90512084960938, 'scale': 3.0}\n",
      "Allocated   (GB): 19.85367441177368\n",
      "Allocated   (GB): 21.883316040039062\n",
      "Allocated   (GB): 21.88331651687622\n",
      "Allocated   (GB): 21.88332223892212\n",
      "{'reward': -0.5901031494140625, 'kl_ref_theta_star': 76.5, 'kl_theta_ref': 0.0891001895070076, 'kl_theta_theta_star': 121.14051055908203, 'scale': 3.0}\n",
      "Allocated   (GB): 19.17838191986084\n",
      "Allocated   (GB): 22.725820541381836\n",
      "Allocated   (GB): 22.72581386566162\n",
      "Allocated   (GB): 22.725831031799316\n",
      "{'reward': -0.09437370300292969, 'kl_ref_theta_star': 111.5, 'kl_theta_ref': 0.13808473944664001, 'kl_theta_theta_star': 101.3909912109375, 'scale': 3.0}\n",
      "Allocated   (GB): 19.94953727722168\n",
      "Allocated   (GB): 21.917478561401367\n",
      "Allocated   (GB): 21.917479515075684\n",
      "Allocated   (GB): 21.917483806610107\n",
      "{'reward': -0.004638671875, 'kl_ref_theta_star': 125.0, 'kl_theta_ref': 0.059765689074993134, 'kl_theta_theta_star': 64.36870574951172, 'scale': 3.0}\n",
      "Allocated   (GB): 20.209371089935303\n",
      "Allocated   (GB): 22.54826831817627\n",
      "Allocated   (GB): 22.548269271850586\n",
      "Allocated   (GB): 22.548274517059326\n",
      "{'reward': -0.0014133453369140625, 'kl_ref_theta_star': 107.5, 'kl_theta_ref': 0.0032766121439635754, 'kl_theta_theta_star': 117.71211242675781, 'scale': 3.0}\n",
      "Allocated   (GB): 19.657911777496338\n",
      "Allocated   (GB): 21.1925311088562\n",
      "Allocated   (GB): 21.192532062530518\n",
      "Allocated   (GB): 21.192535400390625\n",
      "{'reward': 0.0294952392578125, 'kl_ref_theta_star': 76.0, 'kl_theta_ref': 0.02720506303012371, 'kl_theta_theta_star': 62.63948440551758, 'scale': 3.0}\n",
      "Allocated   (GB): 19.981032848358154\n",
      "Allocated   (GB): 23.35994529724121\n",
      "Allocated   (GB): 23.359943389892578\n",
      "Allocated   (GB): 23.35995578765869\n",
      "{'reward': -0.4268798828125, 'kl_ref_theta_star': 106.5, 'kl_theta_ref': 0.44468849897384644, 'kl_theta_theta_star': 144.76258850097656, 'scale': 3.0}\n",
      "Allocated   (GB): 19.93811845779419\n",
      "Allocated   (GB): 21.971009254455566\n",
      "Allocated   (GB): 21.971010208129883\n",
      "Allocated   (GB): 21.97101593017578\n",
      "{'reward': 0.76055908203125, 'kl_ref_theta_star': 124.5, 'kl_theta_ref': 0.1092214584350586, 'kl_theta_theta_star': 127.84555053710938, 'scale': 3.0}\n",
      "Allocated   (GB): 20.255820274353027\n",
      "Allocated   (GB): 22.632482528686523\n",
      "Allocated   (GB): 22.63248348236084\n",
      "Allocated   (GB): 22.63248872756958\n",
      "{'reward': -0.31929779052734375, 'kl_ref_theta_star': 116.5, 'kl_theta_ref': 0.05008378252387047, 'kl_theta_theta_star': 41.66044616699219, 'scale': 3.0}\n",
      "Allocated   (GB): 19.42427635192871\n",
      "Allocated   (GB): 22.537375450134277\n",
      "Allocated   (GB): 22.53737163543701\n",
      "Allocated   (GB): 22.537384510040283\n",
      "{'reward': -0.23598289489746094, 'kl_ref_theta_star': 101.0, 'kl_theta_ref': 0.005771479569375515, 'kl_theta_theta_star': 127.40265655517578, 'scale': 3.0}\n",
      "Allocated   (GB): 17.02811574935913\n",
      "Allocated   (GB): 20.36294174194336\n",
      "Allocated   (GB): 20.362939834594727\n",
      "Allocated   (GB): 20.362950801849365\n",
      "{'reward': -0.5225067138671875, 'kl_ref_theta_star': 167.0, 'kl_theta_ref': 0.21363678574562073, 'kl_theta_theta_star': 184.1710205078125, 'scale': 3.0}\n",
      "Allocated   (GB): 20.048920154571533\n",
      "Allocated   (GB): 23.633655071258545\n",
      "Allocated   (GB): 23.633653163909912\n",
      "Allocated   (GB): 23.633665084838867\n",
      "{'reward': 1.17962646484375, 'kl_ref_theta_star': 111.5, 'kl_theta_ref': 0.14431197941303253, 'kl_theta_theta_star': 102.47216796875, 'scale': 3.0}\n",
      "Allocated   (GB): 21.181486129760742\n",
      "Allocated   (GB): 24.522645950317383\n",
      "Allocated   (GB): 24.52264976501465\n",
      "Allocated   (GB): 24.52265501022339\n",
      "{'reward': -1.74481201171875, 'kl_ref_theta_star': 142.0, 'kl_theta_ref': 0.07410690188407898, 'kl_theta_theta_star': 62.064369201660156, 'scale': 3.0}\n",
      "Allocated   (GB): 20.57368564605713\n",
      "Allocated   (GB): 25.181373119354248\n",
      "Allocated   (GB): 25.181371212005615\n",
      "Allocated   (GB): 25.18138551712036\n",
      "{'reward': -0.833160400390625, 'kl_ref_theta_star': 107.5, 'kl_theta_ref': 0.49037954211235046, 'kl_theta_theta_star': 145.59457397460938, 'scale': 3.0}\n",
      "Allocated   (GB): 19.97319746017456\n",
      "Allocated   (GB): 21.783953189849854\n",
      "Allocated   (GB): 21.783955097198486\n",
      "Allocated   (GB): 21.783958911895752\n",
      "{'reward': 1.708740234375, 'kl_ref_theta_star': 102.5, 'kl_theta_ref': 0.29562848806381226, 'kl_theta_theta_star': 108.14349365234375, 'scale': 3.0}\n",
      "Allocated   (GB): 20.525615692138672\n",
      "Allocated   (GB): 24.2139310836792\n",
      "Allocated   (GB): 24.2139310836792\n",
      "Allocated   (GB): 24.213942527770996\n",
      "{'reward': 0.268646240234375, 'kl_ref_theta_star': 144.0, 'kl_theta_ref': 0.3459833860397339, 'kl_theta_theta_star': 120.85052490234375, 'scale': 3.0}\n",
      "Allocated   (GB): 19.959778308868408\n",
      "Allocated   (GB): 22.38936996459961\n",
      "Allocated   (GB): 22.38936948776245\n",
      "Allocated   (GB): 22.389376640319824\n",
      "{'reward': -0.210540771484375, 'kl_ref_theta_star': 102.0, 'kl_theta_ref': 0.08874481916427612, 'kl_theta_theta_star': 149.07315063476562, 'scale': 3.0}\n",
      "Allocated   (GB): 19.782545566558838\n",
      "Allocated   (GB): 21.540244579315186\n",
      "Allocated   (GB): 21.540245056152344\n",
      "Allocated   (GB): 21.540249347686768\n",
      "{'reward': 0.2094879150390625, 'kl_ref_theta_star': 113.5, 'kl_theta_ref': 0.14303173124790192, 'kl_theta_theta_star': 89.02532196044922, 'scale': 3.0}\n",
      "Allocated   (GB): 19.96852731704712\n",
      "Allocated   (GB): 22.18684148788452\n",
      "Allocated   (GB): 22.18684196472168\n",
      "Allocated   (GB): 22.18684720993042\n",
      "{'reward': -0.024417877197265625, 'kl_ref_theta_star': 90.0, 'kl_theta_ref': 0.030026372522115707, 'kl_theta_theta_star': 99.96908569335938, 'scale': 3.0}\n",
      "Allocated   (GB): 20.2223858833313\n",
      "Allocated   (GB): 21.324227333068848\n",
      "Allocated   (GB): 21.324231147766113\n",
      "Allocated   (GB): 21.324230670928955\n",
      "{'reward': 0.0274505615234375, 'kl_ref_theta_star': 111.0, 'kl_theta_ref': 0.05181598663330078, 'kl_theta_theta_star': 70.49085998535156, 'scale': 3.0}\n",
      "Allocated   (GB): 20.346960067749023\n",
      "Allocated   (GB): 23.22893238067627\n",
      "Allocated   (GB): 23.228933334350586\n",
      "Allocated   (GB): 23.228941440582275\n",
      "{'reward': 0.3409423828125, 'kl_ref_theta_star': 103.0, 'kl_theta_ref': 0.13247020542621613, 'kl_theta_theta_star': 85.62030792236328, 'scale': 3.0}\n",
      "Allocated   (GB): 20.496368408203125\n",
      "Allocated   (GB): 24.65240240097046\n",
      "Allocated   (GB): 24.652400493621826\n",
      "Allocated   (GB): 24.652413368225098\n",
      "{'reward': -1.390594482421875, 'kl_ref_theta_star': 85.5, 'kl_theta_ref': 0.1785106658935547, 'kl_theta_theta_star': 97.86906433105469, 'scale': 3.0}\n",
      "Allocated   (GB): 20.04169511795044\n",
      "Allocated   (GB): 22.507042407989502\n",
      "Allocated   (GB): 22.50704336166382\n",
      "Allocated   (GB): 22.50705051422119\n",
      "{'reward': 0.55999755859375, 'kl_ref_theta_star': 149.0, 'kl_theta_ref': 0.1706080436706543, 'kl_theta_theta_star': 140.1666259765625, 'scale': 3.0}\n",
      "Allocated   (GB): 20.228993892669678\n",
      "Allocated   (GB): 22.439867973327637\n",
      "Allocated   (GB): 22.43986988067627\n",
      "Allocated   (GB): 22.43987512588501\n",
      "{'reward': -1.31884765625, 'kl_ref_theta_star': 107.5, 'kl_theta_ref': 0.21065708994865417, 'kl_theta_theta_star': 89.48548889160156, 'scale': 3.0}\n",
      "Allocated   (GB): 19.870635509490967\n",
      "Allocated   (GB): 21.998519897460938\n",
      "Allocated   (GB): 21.998520374298096\n",
      "Allocated   (GB): 21.998525619506836\n",
      "{'reward': 0.1098785400390625, 'kl_ref_theta_star': 100.0, 'kl_theta_ref': 0.07239726930856705, 'kl_theta_theta_star': 91.6741943359375, 'scale': 3.0}\n",
      "Allocated   (GB): 19.40651559829712\n",
      "Allocated   (GB): 20.33849287033081\n",
      "Allocated   (GB): 20.338493824005127\n",
      "Allocated   (GB): 20.338496208190918\n",
      "{'reward': 0.11211395263671875, 'kl_ref_theta_star': 34.25, 'kl_theta_ref': 0.0046675982885062695, 'kl_theta_theta_star': 37.812957763671875, 'scale': 3.0}\n",
      "Allocated   (GB): 17.81891393661499\n",
      "Allocated   (GB): 21.207147121429443\n",
      "Allocated   (GB): 21.207148551940918\n",
      "Allocated   (GB): 21.20715570449829\n",
      "{'reward': -0.090240478515625, 'kl_ref_theta_star': 62.5, 'kl_theta_ref': 0.13836893439292908, 'kl_theta_theta_star': 113.61914825439453, 'scale': 3.0}\n",
      "Allocated   (GB): 20.555097579956055\n",
      "Allocated   (GB): 23.82215976715088\n",
      "Allocated   (GB): 23.822160720825195\n",
      "Allocated   (GB): 23.82216787338257\n",
      "{'reward': 0.009889602661132812, 'kl_ref_theta_star': 117.5, 'kl_theta_ref': 0.008326297625899315, 'kl_theta_theta_star': 104.01435852050781, 'scale': 3.0}\n",
      "Allocated   (GB): 19.626978874206543\n",
      "Allocated   (GB): 21.17552947998047\n",
      "Allocated   (GB): 21.175530433654785\n",
      "Allocated   (GB): 21.175533771514893\n",
      "{'reward': 0.11269378662109375, 'kl_ref_theta_star': 55.5, 'kl_theta_ref': 0.008027010597288609, 'kl_theta_theta_star': 55.483360290527344, 'scale': 3.0}\n",
      "Allocated   (GB): 20.05220651626587\n",
      "Allocated   (GB): 22.459133625030518\n",
      "Allocated   (GB): 22.459135055541992\n",
      "Allocated   (GB): 22.45914125442505\n",
      "{'reward': 0.74053955078125, 'kl_ref_theta_star': 118.5, 'kl_theta_ref': 0.06702722609043121, 'kl_theta_theta_star': 114.00286865234375, 'scale': 3.0}\n",
      "Allocated   (GB): 20.22988748550415\n",
      "Allocated   (GB): 22.60922145843506\n",
      "Allocated   (GB): 22.609222412109375\n",
      "Allocated   (GB): 22.609227657318115\n",
      "{'reward': 0.012508392333984375, 'kl_ref_theta_star': 110.0, 'kl_theta_ref': 0.006313172169029713, 'kl_theta_theta_star': 84.60366821289062, 'scale': 3.0}\n",
      "Allocated   (GB): 19.558699131011963\n",
      "Allocated   (GB): 21.10194444656372\n",
      "Allocated   (GB): 21.10194444656372\n",
      "Allocated   (GB): 21.101948738098145\n",
      "{'reward': 0.279266357421875, 'kl_ref_theta_star': 68.5, 'kl_theta_ref': 0.09028130769729614, 'kl_theta_theta_star': 94.71316528320312, 'scale': 3.0}\n",
      "Allocated   (GB): 19.78820562362671\n",
      "Allocated   (GB): 22.56708526611328\n",
      "Allocated   (GB): 22.567084312438965\n",
      "Allocated   (GB): 22.56709337234497\n",
      "{'reward': 0.14838409423828125, 'kl_ref_theta_star': 136.0, 'kl_theta_ref': 0.06197712942957878, 'kl_theta_theta_star': 65.87296295166016, 'scale': 3.0}\n",
      "Allocated   (GB): 20.01607894897461\n",
      "Allocated   (GB): 22.474432468414307\n",
      "Allocated   (GB): 22.474432945251465\n",
      "Allocated   (GB): 22.47443914413452\n",
      "{'reward': -0.051166534423828125, 'kl_ref_theta_star': 82.5, 'kl_theta_ref': 0.030239656567573547, 'kl_theta_theta_star': 146.1976318359375, 'scale': 3.0}\n",
      "Allocated   (GB): 20.221379280090332\n",
      "Allocated   (GB): 23.113059997558594\n",
      "Allocated   (GB): 23.113059997558594\n",
      "Allocated   (GB): 23.1130690574646\n",
      "{'reward': -0.415283203125, 'kl_ref_theta_star': 84.5, 'kl_theta_ref': 0.2954956293106079, 'kl_theta_theta_star': 103.0340576171875, 'scale': 3.0}\n",
      "Allocated   (GB): 20.229888439178467\n",
      "Allocated   (GB): 22.934614181518555\n",
      "Allocated   (GB): 22.934614181518555\n",
      "Allocated   (GB): 22.934622287750244\n",
      "{'reward': -0.80126953125, 'kl_ref_theta_star': 140.0, 'kl_theta_ref': 0.34561336040496826, 'kl_theta_theta_star': 148.58331298828125, 'scale': 3.0}\n",
      "Allocated   (GB): 19.569389820098877\n",
      "Allocated   (GB): 21.04465675354004\n",
      "Allocated   (GB): 21.04465675354004\n",
      "Allocated   (GB): 21.044661045074463\n",
      "{'reward': 0.1465473175048828, 'kl_ref_theta_star': 75.5, 'kl_theta_ref': 0.0223458893597126, 'kl_theta_theta_star': 109.00491333007812, 'scale': 3.0}\n",
      "Allocated   (GB): 19.847444534301758\n",
      "Allocated   (GB): 21.82775068283081\n",
      "Allocated   (GB): 21.827751636505127\n",
      "Allocated   (GB): 21.82775592803955\n",
      "{'reward': -0.476837158203125, 'kl_ref_theta_star': 109.5, 'kl_theta_ref': 0.10264816880226135, 'kl_theta_theta_star': 92.25747680664062, 'scale': 3.0}\n",
      "Allocated   (GB): 19.391348838806152\n",
      "Allocated   (GB): 21.015816688537598\n",
      "Allocated   (GB): 21.015816688537598\n",
      "Allocated   (GB): 21.01582145690918\n",
      "{'reward': 0.342315673828125, 'kl_ref_theta_star': 56.75, 'kl_theta_ref': 0.15994557738304138, 'kl_theta_theta_star': 105.6472396850586, 'scale': 3.0}\n",
      "Allocated   (GB): 20.247045040130615\n",
      "Allocated   (GB): 23.511112213134766\n",
      "Allocated   (GB): 23.51111125946045\n",
      "Allocated   (GB): 23.51112127304077\n",
      "{'reward': -1.4534912109375, 'kl_ref_theta_star': 42.5, 'kl_theta_ref': 0.2821575701236725, 'kl_theta_theta_star': 128.63357543945312, 'scale': 3.0}\n",
      "Allocated   (GB): 19.674318313598633\n",
      "Allocated   (GB): 21.57425308227539\n",
      "Allocated   (GB): 21.57425308227539\n",
      "Allocated   (GB): 21.57425880432129\n",
      "{'reward': 0.149322509765625, 'kl_ref_theta_star': 121.5, 'kl_theta_ref': 0.2011459469795227, 'kl_theta_theta_star': 107.8487548828125, 'scale': 3.0}\n",
      "Allocated   (GB): 19.945714473724365\n",
      "Allocated   (GB): 22.742295742034912\n",
      "Allocated   (GB): 22.742294788360596\n",
      "Allocated   (GB): 22.7423038482666\n",
      "{'reward': -0.259979248046875, 'kl_ref_theta_star': 107.0, 'kl_theta_ref': 0.041044142097234726, 'kl_theta_theta_star': 67.09357452392578, 'scale': 3.0}\n",
      "Allocated   (GB): 16.768847465515137\n",
      "Allocated   (GB): 19.944610118865967\n",
      "Allocated   (GB): 19.944607257843018\n",
      "Allocated   (GB): 19.944619178771973\n",
      "{'reward': 0.4393157958984375, 'kl_ref_theta_star': 157.0, 'kl_theta_ref': 0.4040479063987732, 'kl_theta_theta_star': 122.42108154296875, 'scale': 3.0}\n",
      "Allocated   (GB): 19.83370590209961\n",
      "Allocated   (GB): 22.725818634033203\n",
      "Allocated   (GB): 22.72581720352173\n",
      "Allocated   (GB): 22.72582721710205\n",
      "{'reward': 0.184814453125, 'kl_ref_theta_star': 80.0, 'kl_theta_ref': 0.14736881852149963, 'kl_theta_theta_star': 98.1944351196289, 'scale': 3.0}\n",
      "Allocated   (GB): 19.433960437774658\n",
      "Allocated   (GB): 23.123947620391846\n",
      "Allocated   (GB): 23.123942375183105\n",
      "Allocated   (GB): 23.123958587646484\n",
      "{'reward': -0.2969818115234375, 'kl_ref_theta_star': 73.0, 'kl_theta_ref': 0.04552682489156723, 'kl_theta_theta_star': 28.795032501220703, 'scale': 3.0}\n",
      "Allocated   (GB): 19.752721786499023\n",
      "Allocated   (GB): 21.73104763031006\n",
      "Allocated   (GB): 21.73104763031006\n",
      "Allocated   (GB): 21.7310528755188\n",
      "{'reward': 0.3281517028808594, 'kl_ref_theta_star': 104.0, 'kl_theta_ref': 0.056857768446207047, 'kl_theta_theta_star': 57.97813415527344, 'scale': 3.0}\n",
      "Allocated   (GB): 19.3439679145813\n",
      "Allocated   (GB): 20.69626522064209\n",
      "Allocated   (GB): 20.69626474380493\n",
      "Allocated   (GB): 20.696269512176514\n",
      "{'reward': -0.30175018310546875, 'kl_ref_theta_star': 96.5, 'kl_theta_ref': 0.09356987476348877, 'kl_theta_theta_star': 88.44739532470703, 'scale': 3.0}\n",
      "Allocated   (GB): 19.795559406280518\n",
      "Allocated   (GB): 21.716547966003418\n",
      "Allocated   (GB): 21.716548919677734\n",
      "Allocated   (GB): 21.716553211212158\n",
      "{'reward': -0.09536361694335938, 'kl_ref_theta_star': 83.5, 'kl_theta_ref': 0.03140447661280632, 'kl_theta_theta_star': 61.81793975830078, 'scale': 3.0}\n",
      "Allocated   (GB): 19.749746799468994\n",
      "Allocated   (GB): 21.624531269073486\n",
      "Allocated   (GB): 21.624531269073486\n",
      "Allocated   (GB): 21.624536514282227\n",
      "{'reward': -0.8359146118164062, 'kl_ref_theta_star': 94.5, 'kl_theta_ref': 0.03492756932973862, 'kl_theta_theta_star': 81.45125579833984, 'scale': 3.0}\n",
      "Allocated   (GB): 19.483158111572266\n",
      "Allocated   (GB): 20.133896350860596\n",
      "Allocated   (GB): 20.13389825820923\n",
      "Allocated   (GB): 20.133898735046387\n",
      "{'reward': -0.2956085205078125, 'kl_ref_theta_star': 176.0, 'kl_theta_ref': 0.025099612772464752, 'kl_theta_theta_star': 45.274070739746094, 'scale': 3.0}\n",
      "Allocated   (GB): 19.813272953033447\n",
      "Allocated   (GB): 23.21895170211792\n",
      "Allocated   (GB): 23.21894931793213\n",
      "Allocated   (GB): 23.218961238861084\n",
      "{'reward': -0.5120391845703125, 'kl_ref_theta_star': 115.5, 'kl_theta_ref': 0.3168673515319824, 'kl_theta_theta_star': 185.11795043945312, 'scale': 3.0}\n",
      "Allocated   (GB): 19.41624402999878\n",
      "Allocated   (GB): 20.456523895263672\n",
      "Allocated   (GB): 20.45652484893799\n",
      "Allocated   (GB): 20.45652723312378\n",
      "{'reward': -0.014936447143554688, 'kl_ref_theta_star': 126.0, 'kl_theta_ref': 0.005387583747506142, 'kl_theta_theta_star': 118.0072250366211, 'scale': 3.0}\n",
      "Allocated   (GB): 19.68288278579712\n",
      "Allocated   (GB): 21.804017543792725\n",
      "Allocated   (GB): 21.804017066955566\n",
      "Allocated   (GB): 21.80402374267578\n",
      "{'reward': -0.045379638671875, 'kl_ref_theta_star': 141.0, 'kl_theta_ref': 0.0791657418012619, 'kl_theta_theta_star': 95.44453430175781, 'scale': 3.0}\n",
      "Allocated   (GB): 20.295311450958252\n",
      "Allocated   (GB): 22.340074062347412\n",
      "Allocated   (GB): 22.340075492858887\n",
      "Allocated   (GB): 22.34007978439331\n",
      "{'reward': -0.3382110595703125, 'kl_ref_theta_star': 73.5, 'kl_theta_ref': 0.07544606924057007, 'kl_theta_theta_star': 84.4581298828125, 'scale': 3.0}\n",
      "Allocated   (GB): 20.357888221740723\n",
      "Allocated   (GB): 23.151761054992676\n",
      "Allocated   (GB): 23.151762008666992\n",
      "Allocated   (GB): 23.151768684387207\n",
      "{'reward': 1.582305908203125, 'kl_ref_theta_star': 108.5, 'kl_theta_ref': 0.2013472318649292, 'kl_theta_theta_star': 129.40402221679688, 'scale': 3.0}\n",
      "Allocated   (GB): 20.26213026046753\n",
      "Allocated   (GB): 22.638754844665527\n",
      "Allocated   (GB): 22.638756275177002\n",
      "Allocated   (GB): 22.63876247406006\n",
      "{'reward': -0.19854736328125, 'kl_ref_theta_star': 96.5, 'kl_theta_ref': 0.06330101937055588, 'kl_theta_theta_star': 65.5809326171875, 'scale': 3.0}\n",
      "Allocated   (GB): 20.247962474822998\n",
      "Allocated   (GB): 22.42298173904419\n",
      "Allocated   (GB): 22.422983169555664\n",
      "Allocated   (GB): 22.422987461090088\n",
      "{'reward': 0.90606689453125, 'kl_ref_theta_star': 103.0, 'kl_theta_ref': 0.04710366204380989, 'kl_theta_theta_star': 92.7792739868164, 'scale': 3.0}\n",
      "Allocated   (GB): 19.63555908203125\n",
      "Allocated   (GB): 21.33428716659546\n",
      "Allocated   (GB): 21.334287643432617\n",
      "Allocated   (GB): 21.33429193496704\n",
      "{'reward': -0.26519012451171875, 'kl_ref_theta_star': 108.5, 'kl_theta_ref': 0.011531154625117779, 'kl_theta_theta_star': 65.2208251953125, 'scale': 3.0}\n",
      "Allocated   (GB): 17.447439193725586\n",
      "Allocated   (GB): 20.430941581726074\n",
      "Allocated   (GB): 20.430942058563232\n",
      "Allocated   (GB): 20.430949211120605\n",
      "{'reward': 0.035404205322265625, 'kl_ref_theta_star': 85.5, 'kl_theta_ref': 0.21704578399658203, 'kl_theta_theta_star': 150.51502990722656, 'scale': 3.0}\n",
      "Allocated   (GB): 20.6085205078125\n",
      "Allocated   (GB): 24.003567218780518\n",
      "Allocated   (GB): 24.003567695617676\n",
      "Allocated   (GB): 24.003576278686523\n",
      "{'reward': 1.364288330078125, 'kl_ref_theta_star': 163.0, 'kl_theta_ref': 0.1628066599369049, 'kl_theta_theta_star': 88.83333587646484, 'scale': 3.0}\n",
      "Allocated   (GB): 19.82623815536499\n",
      "Allocated   (GB): 21.65831995010376\n",
      "Allocated   (GB): 21.658321380615234\n",
      "Allocated   (GB): 21.6583251953125\n",
      "{'reward': 0.026123046875, 'kl_ref_theta_star': 78.5, 'kl_theta_ref': 0.3427094519138336, 'kl_theta_theta_star': 85.08177185058594, 'scale': 3.0}\n",
      "Allocated   (GB): 20.00390911102295\n",
      "Allocated   (GB): 23.203773975372314\n",
      "Allocated   (GB): 23.203773021697998\n",
      "Allocated   (GB): 23.20378303527832\n",
      "{'reward': -1.1690902709960938, 'kl_ref_theta_star': 138.0, 'kl_theta_ref': 0.1967197209596634, 'kl_theta_theta_star': 131.869140625, 'scale': 3.0}\n",
      "Allocated   (GB): 19.83496332168579\n",
      "Allocated   (GB): 21.82086181640625\n",
      "Allocated   (GB): 21.820862770080566\n",
      "Allocated   (GB): 21.82086706161499\n",
      "{'reward': 0.10333251953125, 'kl_ref_theta_star': 90.5, 'kl_theta_ref': 0.058562468737363815, 'kl_theta_theta_star': 91.24020385742188, 'scale': 3.0}\n",
      "Allocated   (GB): 20.050949573516846\n",
      "Allocated   (GB): 22.68429946899414\n",
      "Allocated   (GB): 22.6842999458313\n",
      "Allocated   (GB): 22.684306621551514\n",
      "{'reward': -0.084381103515625, 'kl_ref_theta_star': 33.25, 'kl_theta_ref': 0.08169449865818024, 'kl_theta_theta_star': 65.98596954345703, 'scale': 3.0}\n",
      "Allocated   (GB): 19.539609909057617\n",
      "Allocated   (GB): 20.58416986465454\n",
      "Allocated   (GB): 20.584170818328857\n",
      "Allocated   (GB): 20.58417320251465\n",
      "{'reward': -0.23956298828125, 'kl_ref_theta_star': 60.25, 'kl_theta_ref': 0.022801391780376434, 'kl_theta_theta_star': 40.21394348144531, 'scale': 3.0}\n",
      "Allocated   (GB): 20.3179612159729\n",
      "Allocated   (GB): 22.911283016204834\n",
      "Allocated   (GB): 22.911283493041992\n",
      "Allocated   (GB): 22.91128969192505\n",
      "{'reward': 0.11787033081054688, 'kl_ref_theta_star': 79.0, 'kl_theta_ref': 0.006967843044549227, 'kl_theta_theta_star': 119.21437072753906, 'scale': 3.0}\n",
      "Allocated   (GB): 19.425183296203613\n",
      "Allocated   (GB): 20.334749698638916\n",
      "Allocated   (GB): 20.334750652313232\n",
      "Allocated   (GB): 20.334753036499023\n",
      "{'reward': 0.000946044921875, 'kl_ref_theta_star': 66.5, 'kl_theta_ref': 0.039382487535476685, 'kl_theta_theta_star': 62.56242752075195, 'scale': 3.0}\n",
      "Allocated   (GB): 19.752037048339844\n",
      "Allocated   (GB): 23.571860790252686\n",
      "Allocated   (GB): 23.57185649871826\n",
      "Allocated   (GB): 23.571871757507324\n",
      "{'reward': -0.667755126953125, 'kl_ref_theta_star': 196.0, 'kl_theta_ref': 0.1527179479598999, 'kl_theta_theta_star': 112.7904052734375, 'scale': 3.0}\n",
      "Allocated   (GB): 20.32343626022339\n",
      "Allocated   (GB): 22.256790161132812\n",
      "Allocated   (GB): 22.256792068481445\n",
      "Allocated   (GB): 22.256795406341553\n",
      "{'reward': 1.3477935791015625, 'kl_ref_theta_star': 110.0, 'kl_theta_ref': 0.12602251768112183, 'kl_theta_theta_star': 205.66944885253906, 'scale': 3.0}\n",
      "Allocated   (GB): 19.763731002807617\n",
      "Allocated   (GB): 21.595494270324707\n",
      "Allocated   (GB): 21.595494270324707\n",
      "Allocated   (GB): 21.595499992370605\n",
      "{'reward': 0.7394866943359375, 'kl_ref_theta_star': 77.0, 'kl_theta_ref': 0.08649863302707672, 'kl_theta_theta_star': 106.26516723632812, 'scale': 3.0}\n",
      "Allocated   (GB): 20.056881427764893\n",
      "Allocated   (GB): 22.591556072235107\n",
      "Allocated   (GB): 22.591556549072266\n",
      "Allocated   (GB): 22.591562747955322\n",
      "{'reward': 0.39089202880859375, 'kl_ref_theta_star': 112.5, 'kl_theta_ref': 0.09835150837898254, 'kl_theta_theta_star': 132.12570190429688, 'scale': 3.0}\n",
      "Allocated   (GB): 19.551668167114258\n",
      "Allocated   (GB): 21.322365760803223\n",
      "Allocated   (GB): 21.322365283966064\n",
      "Allocated   (GB): 21.322371006011963\n",
      "{'reward': -0.3195037841796875, 'kl_ref_theta_star': 52.25, 'kl_theta_ref': 0.46396324038505554, 'kl_theta_theta_star': 87.05915832519531, 'scale': 3.0}\n",
      "Allocated   (GB): 20.324785709381104\n",
      "Allocated   (GB): 22.49845790863037\n",
      "Allocated   (GB): 22.498459339141846\n",
      "Allocated   (GB): 22.498464107513428\n",
      "{'reward': -0.3315582275390625, 'kl_ref_theta_star': 64.5, 'kl_theta_ref': 0.086371511220932, 'kl_theta_theta_star': 88.97312927246094, 'scale': 3.0}\n",
      "Allocated   (GB): 20.552791595458984\n",
      "Allocated   (GB): 23.04418659210205\n",
      "Allocated   (GB): 23.044189453125\n",
      "Allocated   (GB): 23.04419469833374\n",
      "{'reward': -1.536773681640625, 'kl_ref_theta_star': 98.0, 'kl_theta_ref': 0.14393071830272675, 'kl_theta_theta_star': 85.10163879394531, 'scale': 3.0}\n",
      "Allocated   (GB): 16.900362968444824\n",
      "Allocated   (GB): 18.55093812942505\n",
      "Allocated   (GB): 18.550938606262207\n",
      "Allocated   (GB): 18.55094289779663\n",
      "{'reward': -0.706512451171875, 'kl_ref_theta_star': 129.0, 'kl_theta_ref': 0.07141623646020889, 'kl_theta_theta_star': 116.71051025390625, 'scale': 3.0}\n",
      "Allocated   (GB): 19.990429401397705\n",
      "Allocated   (GB): 22.758437633514404\n",
      "Allocated   (GB): 22.758436679840088\n",
      "Allocated   (GB): 22.758445739746094\n",
      "{'reward': -0.676025390625, 'kl_ref_theta_star': 98.0, 'kl_theta_ref': 0.30536770820617676, 'kl_theta_theta_star': 155.45896911621094, 'scale': 3.0}\n",
      "Allocated   (GB): 19.63505458831787\n",
      "Allocated   (GB): 21.116915225982666\n",
      "Allocated   (GB): 21.11691665649414\n",
      "Allocated   (GB): 21.11691904067993\n",
      "{'reward': -0.5439605712890625, 'kl_ref_theta_star': 119.5, 'kl_theta_ref': 0.02540554106235504, 'kl_theta_theta_star': 93.19342803955078, 'scale': 3.0}\n",
      "Allocated   (GB): 20.673834800720215\n",
      "Allocated   (GB): 22.42255210876465\n",
      "Allocated   (GB): 22.42255687713623\n",
      "Allocated   (GB): 22.42255735397339\n",
      "{'reward': 1.2529296875, 'kl_ref_theta_star': 214.0, 'kl_theta_ref': 0.08585172146558762, 'kl_theta_theta_star': 131.38563537597656, 'scale': 3.0}\n",
      "Allocated   (GB): 19.976343154907227\n",
      "Allocated   (GB): 21.07583999633789\n",
      "Allocated   (GB): 21.07584285736084\n",
      "Allocated   (GB): 21.075843334197998\n",
      "{'reward': 1.73895263671875, 'kl_ref_theta_star': 200.0, 'kl_theta_ref': 0.07839582115411758, 'kl_theta_theta_star': 163.75827026367188, 'scale': 3.0}\n",
      "Allocated   (GB): 19.637750148773193\n",
      "Allocated   (GB): 21.0778489112854\n",
      "Allocated   (GB): 21.077850341796875\n",
      "Allocated   (GB): 21.077852725982666\n",
      "{'reward': 0.2647552490234375, 'kl_ref_theta_star': 127.5, 'kl_theta_ref': 0.04973478987812996, 'kl_theta_theta_star': 81.0341796875, 'scale': 3.0}\n",
      "Allocated   (GB): 19.987792015075684\n",
      "Allocated   (GB): 22.613945960998535\n",
      "Allocated   (GB): 22.613945960998535\n",
      "Allocated   (GB): 22.613954067230225\n",
      "{'reward': 2.08746337890625, 'kl_ref_theta_star': 78.0, 'kl_theta_ref': 0.3093907833099365, 'kl_theta_theta_star': 133.21099853515625, 'scale': 3.0}\n",
      "Allocated   (GB): 20.253596305847168\n",
      "Allocated   (GB): 23.775517463684082\n",
      "Allocated   (GB): 23.775516510009766\n",
      "Allocated   (GB): 23.775527954101562\n",
      "{'reward': 1.3497314453125, 'kl_ref_theta_star': 80.0, 'kl_theta_ref': 0.29170629382133484, 'kl_theta_theta_star': 91.6299819946289, 'scale': 3.0}\n",
      "Allocated   (GB): 20.011563301086426\n",
      "Allocated   (GB): 23.31273889541626\n",
      "Allocated   (GB): 23.312737941741943\n",
      "Allocated   (GB): 23.312747478485107\n",
      "{'reward': 0.2879486083984375, 'kl_ref_theta_star': 134.0, 'kl_theta_ref': 0.099811851978302, 'kl_theta_theta_star': 139.59207153320312, 'scale': 3.0}\n",
      "Allocated   (GB): 19.305434703826904\n",
      "Allocated   (GB): 21.51997995376587\n",
      "Allocated   (GB): 21.519977569580078\n",
      "Allocated   (GB): 21.519986152648926\n",
      "{'reward': -0.1535472869873047, 'kl_ref_theta_star': 103.5, 'kl_theta_ref': 0.028730561956763268, 'kl_theta_theta_star': 113.78813171386719, 'scale': 3.0}\n",
      "Allocated   (GB): 19.83650541305542\n",
      "Allocated   (GB): 21.531957149505615\n",
      "Allocated   (GB): 21.53195858001709\n",
      "Allocated   (GB): 21.531961917877197\n",
      "{'reward': 1.08099365234375, 'kl_ref_theta_star': 195.0, 'kl_theta_ref': 0.06378237158060074, 'kl_theta_theta_star': 123.97993469238281, 'scale': 3.0}\n",
      "Allocated   (GB): 20.426319122314453\n",
      "Allocated   (GB): 24.235914707183838\n",
      "Allocated   (GB): 24.23591375350952\n",
      "Allocated   (GB): 24.235926151275635\n",
      "{'reward': 0.71124267578125, 'kl_ref_theta_star': 122.5, 'kl_theta_ref': 0.36428433656692505, 'kl_theta_theta_star': 160.71229553222656, 'scale': 3.0}\n",
      "Allocated   (GB): 19.080513954162598\n",
      "Allocated   (GB): 22.882388591766357\n",
      "Allocated   (GB): 22.882381439208984\n",
      "Allocated   (GB): 22.882399559020996\n",
      "{'reward': 0.05086326599121094, 'kl_ref_theta_star': 120.5, 'kl_theta_ref': 0.007984493859112263, 'kl_theta_theta_star': 120.94886779785156, 'scale': 3.0}\n",
      "Allocated   (GB): 19.684842109680176\n",
      "Allocated   (GB): 21.32682752609253\n",
      "Allocated   (GB): 21.326828002929688\n",
      "Allocated   (GB): 21.32683229446411\n",
      "{'reward': -0.1331787109375, 'kl_ref_theta_star': 89.0, 'kl_theta_ref': 0.0926409438252449, 'kl_theta_theta_star': 63.698486328125, 'scale': 3.0}\n",
      "Allocated   (GB): 20.49033832550049\n",
      "Allocated   (GB): 23.264923572540283\n",
      "Allocated   (GB): 23.264925003051758\n",
      "Allocated   (GB): 23.264931678771973\n",
      "{'reward': -0.7222900390625, 'kl_ref_theta_star': 94.0, 'kl_theta_ref': 0.177863210439682, 'kl_theta_theta_star': 168.58706665039062, 'scale': 3.0}\n",
      "Allocated   (GB): 20.75913906097412\n",
      "Allocated   (GB): 24.51025915145874\n",
      "Allocated   (GB): 24.510260105133057\n",
      "Allocated   (GB): 24.510268211364746\n",
      "{'reward': 0.21195030212402344, 'kl_ref_theta_star': 48.25, 'kl_theta_ref': 0.06835122406482697, 'kl_theta_theta_star': 85.13771057128906, 'scale': 3.0}\n",
      "Allocated   (GB): 16.963325023651123\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     12\u001b[39m preference_pipeline = PairRMPipeline(\n\u001b[32m     13\u001b[39m     model_name_or_path = training_args.preference_model_id,\n\u001b[32m     14\u001b[39m )\n\u001b[32m     16\u001b[39m trainer = DRPOTrainer(\n\u001b[32m     17\u001b[39m     model=target_policy_model,\n\u001b[32m     18\u001b[39m     ref_model=ref_policy_model,\n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m     args=training_args\n\u001b[32m     24\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/miniconda3/envs/myenv/lib/python3.11/site-packages/transformers/trainer.py:2238\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2236\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2237\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2238\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2239\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2242\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2243\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/miniconda3/envs/myenv/lib/python3.11/site-packages/transformers/trainer.py:2582\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2575\u001b[39m context = (\n\u001b[32m   2576\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2577\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2578\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2579\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2580\u001b[39m )\n\u001b[32m   2581\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2582\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2584\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2585\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2586\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2587\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2588\u001b[39m ):\n\u001b[32m   2589\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2590\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/Self_play_DRPO/trl/trainer/drpo_trainer.py:833\u001b[39m, in \u001b[36mDRPOTrainer.training_step\u001b[39m\u001b[34m(self, model, inputs, num_items_in_batch)\u001b[39m\n\u001b[32m    830\u001b[39m per_token_logps = \u001b[38;5;28mself\u001b[39m._forward(model, prompt_ids, prompt_attention_mask, a1_ids, a1_attention_mask, temperature=\u001b[38;5;28mself\u001b[39m.args.forward_temperature)\n\u001b[32m    832\u001b[39m \u001b[38;5;66;03m# sample y* for `num_astar` times\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m prompt_ids_repeated, prompt_attention_mask_repeated, astar_ids, astar_attention_mask = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_attention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnum_astar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    834\u001b[39m contain_eos_token = torch.any(astar_ids == \u001b[38;5;28mself\u001b[39m.processing_class.eos_token_id, dim=-\u001b[32m1\u001b[39m)\n\u001b[32m    835\u001b[39m \u001b[38;5;66;03m# log pi(y*|x) shape(num_astar*batch_size, 1)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/Self_play_DRPO/trl/trainer/drpo_trainer.py:638\u001b[39m, in \u001b[36mDRPOTrainer._generate\u001b[39m\u001b[34m(self, model, prompt_ids, prompt_attention_mask, num_astar, temperature)\u001b[39m\n\u001b[32m    636\u001b[39m         gen_config.penalty_alpha = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m unwrap_model_for_generation(model, \u001b[38;5;28mself\u001b[39m.accelerator, gather_deepspeed3_params=\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m unwrapped_model:\n\u001b[32m--> \u001b[39m\u001b[32m638\u001b[39m     output = \u001b[43munwrapped_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    639\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    640\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    641\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mgen_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    642\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    643\u001b[39m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    644\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    646\u001b[39m completion_ids = output[:, prompt_ids.shape[\u001b[32m1\u001b[39m]:]\n\u001b[32m    647\u001b[39m completion_ids, completion_attention_mask = truncate_right(completion_ids, eos_token_id, pad_token_id)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/miniconda3/envs/myenv/lib/python3.11/site-packages/transformers/generation/utils.py:2634\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2626\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2627\u001b[39m         input_ids=input_ids,\n\u001b[32m   2628\u001b[39m         expand_size=generation_config.num_return_sequences,\n\u001b[32m   2629\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2630\u001b[39m         **model_kwargs,\n\u001b[32m   2631\u001b[39m     )\n\u001b[32m   2633\u001b[39m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2634\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2635\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2636\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2637\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2638\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2639\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2640\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2641\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2642\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2644\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2645\u001b[39m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[32m   2646\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2647\u001b[39m         input_ids=input_ids,\n\u001b[32m   2648\u001b[39m         expand_size=generation_config.num_beams,\n\u001b[32m   2649\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2650\u001b[39m         **model_kwargs,\n\u001b[32m   2651\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/miniconda3/envs/myenv/lib/python3.11/site-packages/transformers/generation/utils.py:3618\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   3616\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   3617\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3618\u001b[39m     outputs = \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3620\u001b[39m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[32m   3621\u001b[39m model_kwargs = \u001b[38;5;28mself\u001b[39m._update_model_kwargs_for_generation(\n\u001b[32m   3622\u001b[39m     outputs,\n\u001b[32m   3623\u001b[39m     model_kwargs,\n\u001b[32m   3624\u001b[39m     is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   3625\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/miniconda3/envs/myenv/lib/python3.11/site-packages/accelerate/utils/operations.py:818\u001b[39m, in \u001b[36mconvert_outputs_to_fp32.<locals>.forward\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    817\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(*args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m818\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/miniconda3/envs/myenv/lib/python3.11/site-packages/accelerate/utils/operations.py:806\u001b[39m, in \u001b[36mConvertOutputsToFp32.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    805\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m806\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:44\u001b[39m, in \u001b[36mautocast_decorator.<locals>.decorate_autocast\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_autocast\u001b[39m(*args, **kwargs):\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/miniconda3/envs/myenv/lib/python3.11/site-packages/transformers/utils/generic.py:959\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    957\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    958\u001b[39m     return_dict = return_dict_passed\n\u001b[32m--> \u001b[39m\u001b[32m959\u001b[39m output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    961\u001b[39m     output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/miniconda3/envs/myenv/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py:450\u001b[39m, in \u001b[36mQwen2ForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    418\u001b[39m \u001b[38;5;129m@can_return_tuple\u001b[39m\n\u001b[32m    419\u001b[39m \u001b[38;5;129m@auto_docstring\u001b[39m\n\u001b[32m    420\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m   (...)\u001b[39m\u001b[32m    431\u001b[39m     **kwargs: Unpack[TransformersKwargs],\n\u001b[32m    432\u001b[39m ) -> CausalLMOutputWithPast:\n\u001b[32m    433\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    434\u001b[39m \u001b[33;03m    Example:\u001b[39;00m\n\u001b[32m    435\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    448\u001b[39m \u001b[33;03m    \"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001b[39;00m\n\u001b[32m    449\u001b[39m \u001b[33;03m    ```\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m450\u001b[39m     outputs: BaseModelOutputWithPast = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    452\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    461\u001b[39m     hidden_states = outputs.last_hidden_state\n\u001b[32m    462\u001b[39m     \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/miniconda3/envs/myenv/lib/python3.11/site-packages/transformers/utils/generic.py:1083\u001b[39m, in \u001b[36mcheck_model_inputs.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1080\u001b[39m                 module.forward = make_capture_wrapper(module, original_forward, key, specs.index)\n\u001b[32m   1081\u001b[39m                 monkey_patched_layers.append((module, original_forward))\n\u001b[32m-> \u001b[39m\u001b[32m1083\u001b[39m outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1084\u001b[39m \u001b[38;5;66;03m# Restore original forward methods\u001b[39;00m\n\u001b[32m   1085\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module, original_forward \u001b[38;5;129;01min\u001b[39;00m monkey_patched_layers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/miniconda3/envs/myenv/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py:379\u001b[39m, in \u001b[36mQwen2Model.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, cache_position, **kwargs)\u001b[39m\n\u001b[32m    376\u001b[39m position_embeddings = \u001b[38;5;28mself\u001b[39m.rotary_emb(hidden_states, position_ids)\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m decoder_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers[: \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers]:\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m     hidden_states = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mattention_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    390\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.norm(hidden_states)\n\u001b[32m    391\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m BaseModelOutputWithPast(\n\u001b[32m    392\u001b[39m     last_hidden_state=hidden_states,\n\u001b[32m    393\u001b[39m     past_key_values=past_key_values \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    394\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/miniconda3/envs/myenv/lib/python3.11/site-packages/transformers/modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/miniconda3/envs/myenv/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py:231\u001b[39m, in \u001b[36mQwen2DecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_value, use_cache, cache_position, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    229\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.input_layernorm(hidden_states)\n\u001b[32m    230\u001b[39m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m hidden_states, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m hidden_states = residual + hidden_states\n\u001b[32m    243\u001b[39m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/miniconda3/envs/myenv/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py:156\u001b[39m, in \u001b[36mQwen2Attention.forward\u001b[39m\u001b[34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[39m\n\u001b[32m    153\u001b[39m value_states = \u001b[38;5;28mself\u001b[39m.v_proj(hidden_states).view(hidden_shape).transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m    155\u001b[39m cos, sin = position_embeddings\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m query_states, key_states = \u001b[43mapply_rotary_pos_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    159\u001b[39m     \u001b[38;5;66;03m# sin and cos are specific to RoPE models; cache_position needed for the static cache\u001b[39;00m\n\u001b[32m    160\u001b[39m     cache_kwargs = {\u001b[33m\"\u001b[39m\u001b[33msin\u001b[39m\u001b[33m\"\u001b[39m: sin, \u001b[33m\"\u001b[39m\u001b[33mcos\u001b[39m\u001b[33m\"\u001b[39m: cos, \u001b[33m\"\u001b[39m\u001b[33mcache_position\u001b[39m\u001b[33m\"\u001b[39m: cache_position}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/miniconda3/envs/myenv/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py:78\u001b[39m, in \u001b[36mapply_rotary_pos_emb\u001b[39m\u001b[34m(q, k, cos, sin, position_ids, unsqueeze_dim)\u001b[39m\n\u001b[32m     76\u001b[39m cos = cos.unsqueeze(unsqueeze_dim)\n\u001b[32m     77\u001b[39m sin = sin.unsqueeze(unsqueeze_dim)\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m q_embed = (q * cos) + (\u001b[43mrotate_half\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m * sin)\n\u001b[32m     79\u001b[39m k_embed = (k * cos) + (rotate_half(k) * sin)\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m q_embed, k_embed\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/miniconda3/envs/myenv/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py:49\u001b[39m, in \u001b[36mrotate_half\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     45\u001b[39m         down_proj = \u001b[38;5;28mself\u001b[39m.down_proj(\u001b[38;5;28mself\u001b[39m.act_fn(\u001b[38;5;28mself\u001b[39m.gate_proj(x)) * \u001b[38;5;28mself\u001b[39m.up_proj(x))\n\u001b[32m     46\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrotate_half\u001b[39m(x):\n\u001b[32m     50\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Rotates half the hidden dims of the input.\"\"\"\u001b[39;00m\n\u001b[32m     51\u001b[39m     x1 = x[..., : x.shape[-\u001b[32m1\u001b[39m] // \u001b[32m2\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._post_run_cell_hook of <wandb.sdk.wandb_init._WandbInit object at 0x785ec02816d0>> (for post_run_cell), with arguments args (<ExecutionResult object at 7860a4131f10, execution_count=2 error_before_exec=None error_in_exec= info=<ExecutionInfo object at 7860a4131590, raw_cell=\"seed = 1234\n",
      "ref_policy_model, ref_policy_tokenizer..\" transformed_cell=\"seed = 1234\n",
      "ref_policy_model, ref_policy_tokenizer..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22413130305f72756e706f64227d/workspace/Self_play_DRPO/self_play_drpo_code/test_codes/drpo_normal_dist.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBrokenPipeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/miniconda3/envs/myenv/lib/python3.11/site-packages/wandb/sdk/wandb_init.py:593\u001b[39m, in \u001b[36m_WandbInit._post_run_cell_hook\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    590\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    592\u001b[39m \u001b[38;5;28mself\u001b[39m._logger.info(\u001b[33m\"\u001b[39m\u001b[33mresuming backend\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m593\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43minterface\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpublish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/miniconda3/envs/myenv/lib/python3.11/site-packages/wandb/sdk/interface/interface.py:787\u001b[39m, in \u001b[36mInterfaceBase.publish_resume\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    785\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpublish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    786\u001b[39m     resume = pb.ResumeRequest()\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_publish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/miniconda3/envs/myenv/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py:294\u001b[39m, in \u001b[36mInterfaceShared._publish_resume\u001b[39m\u001b[34m(self, resume)\u001b[39m\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_publish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m, resume: pb.ResumeRequest) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    293\u001b[39m     rec = \u001b[38;5;28mself\u001b[39m._make_request(resume=resume)\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/miniconda3/envs/myenv/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py:39\u001b[39m, in \u001b[36mInterfaceSock._publish\u001b[39m\u001b[34m(self, record, local)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[33m\"\u001b[39m\u001b[33mpb.Record\u001b[39m\u001b[33m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     38\u001b[39m     \u001b[38;5;28mself\u001b[39m._assign(record)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/miniconda3/envs/myenv/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py:166\u001b[39m, in \u001b[36mSockClient.send_record_publish\u001b[39m\u001b[34m(self, record)\u001b[39m\n\u001b[32m    164\u001b[39m server_req.request_id = record.control.mailbox_slot\n\u001b[32m    165\u001b[39m server_req.record_publish.CopyFrom(record)\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/miniconda3/envs/myenv/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py:146\u001b[39m, in \u001b[36mSockClient.send_server_request\u001b[39m\u001b[34m(self, msg)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: spb.ServerRequest) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/miniconda3/envs/myenv/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py:143\u001b[39m, in \u001b[36mSockClient._send_message\u001b[39m\u001b[34m(self, msg)\u001b[39m\n\u001b[32m    141\u001b[39m header = struct.pack(\u001b[33m\"\u001b[39m\u001b[33m<BI\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mW\u001b[39m\u001b[33m\"\u001b[39m), raw_size)\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/miniconda3/envs/myenv/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py:122\u001b[39m, in \u001b[36mSockClient._sendall_with_error_handle\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    120\u001b[39m start_time = time.monotonic()\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     sent = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m sent == \u001b[32m0\u001b[39m:\n",
      "\u001b[31mBrokenPipeError\u001b[39m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "seed = 1234\n",
    "ref_policy_model, ref_policy_tokenizer = load_model(ref_policy_path)\n",
    "target_policy_model, target_policy_tokenizer = load_model(target_policy_path)\n",
    "dpo_policy_model, dpo_policy_tokenizer = load_model(dpo_policy_path)\n",
    "drpo_train = load_dataset(ds_path, cache_dir=data_cache_path, split = 'train')\n",
    "drpo_train = process_split(drpo_train)\n",
    "drpo_train = drpo_train.shuffle(seed=seed)\n",
    "\n",
    "training_args = DRPOConfig(\n",
    "    **training_args_config\n",
    ")\n",
    "preference_pipeline = PairRMPipeline(\n",
    "    model_name_or_path = training_args.preference_model_id,\n",
    ")\n",
    "\n",
    "trainer = DRPOTrainer(\n",
    "    model=target_policy_model,\n",
    "    ref_model=ref_policy_model,\n",
    "    dpo_model = dpo_policy_model,\n",
    "    preference_model=preference_pipeline,\n",
    "    train_dataset = drpo_train,\n",
    "    processing_class=ref_policy_tokenizer,\n",
    "    args=training_args\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb706217",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_model, tokenizer = load_model(target_policy_path)\n",
    "ref_model, tokenizer = load_model(target_policy_path)\n",
    "target_model.to('cuda')\n",
    "ref_model.to('cuda')\n",
    "drpo_train = load_dataset(ds_path, cache_dir=data_cache_path, split = 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888ae098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "You will be given a definition of a task first, then some input of the task.\n",
      "In this task, you are given a sentence which is either in the Gujarati language or English language. You task is to identify the language of input sentence. Input sentence can be in Gujarari or English language only and also it cannot have two languages at a time.\n",
      "\n",
      "એક ટ્રેન એન્જિન કે જે રેલરોડ ટ્રેક પર મુસાફરી કરેલા ધૂમ્રપાનની સાથે જોડાયેલી છે તેમાં ઘણી પેસેન્જર કાર જોડાયેલી છે.\n",
      "Output:<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = '<|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nYou will be given a definition of a task first, then some input of the task.\\nIn this task, you are given a sentence which is either in the Gujarati language or English language. You task is to identify the language of input sentence. Input sentence can be in Gujarari or English language only and also it cannot have two languages at a time.\\n\\nએક ટ્રેન એન્જિન કે જે રેલરોડ ટ્રેક પર મુસાફરી કરેલા ધૂમ્રપાનની સાથે જોડાયેલી છે તેમાં ઘણી પેસેન્જર કાર જોડાયેલી છે.\\nOutput:<|im_end|>\\n<|im_start|>assistant\\n'\n",
    "print (prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb6e0ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tokenizer(\n",
    "    prompt,\n",
    "    return_tensors = 'pt',\n",
    "    truncation = True,\n",
    "    max_length = 1024\n",
    ").to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72d69e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    }
   ],
   "source": [
    "outputs_1 = ref_model.generate(\n",
    "    **enc,\n",
    "    do_sample = False, \n",
    "    max_new_tokens = 1024,\n",
    "    temperature = 0\n",
    ")\n",
    "outputs_2 = target_model.generate(\n",
    "    **enc,\n",
    "    do_sample = False, \n",
    "    max_new_tokens = 1024,\n",
    "    temperature = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8ae88d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
